{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def check_url_accessibility(url):\n",
    "    response = requests.head(url)\n",
    "    if response.status_code == 200:\n",
    "        print(\"URL is accessible\")\n",
    "    else:\n",
    "        print(\"URL is not accessible\")\n",
    "\n",
    "# URL to check\n",
    "url = \"https://www2.census.gov/programs-surveys/popest/datasets/\"\n",
    "check_url_accessibility(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def download_data(url, filename):\n",
    "    os.system(f\"wget {url} -O {filename}\")\n",
    "\n",
    "# URL and filename\n",
    "data_url = \"https://www2.census.gov/programs-surveys/popest/datasets/\"\n",
    "data_filename = \"data.zip\"\n",
    "download_data(data_url, data_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_hdfs(local_path, hdfs_path):\n",
    "    os.system(f\"hadoop fs -put {local_path} {hdfs_path}\")\n",
    "\n",
    "# Paths\n",
    "local_file_path = \"data.zip\"\n",
    "hdfs_file_path = \"/user/hadoop/data.zip\"\n",
    "upload_to_hdfs(local_file_path, hdfs_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def create_hive_table():\n",
    "    hive_query = \"\"\"\n",
    "    CREATE DATABASE IF NOT EXISTS census_data;\n",
    "    USE census_data;\n",
    "    CREATE EXTERNAL TABLE IF NOT EXISTS population_data (\n",
    "        id INT,\n",
    "        name STRING,\n",
    "        value DOUBLE\n",
    "    )\n",
    "    ROW FORMAT DELIMITED\n",
    "    FIELDS TERMINATED BY ','\n",
    "    LOCATION '/user/hadoop/data/';\n",
    "    \"\"\"\n",
    "    subprocess.run([\"hive\", \"-e\", hive_query])\n",
    "\n",
    "def load_data_into_hive():\n",
    "    hive_query = \"LOAD DATA INPATH '/user/hadoop/data.zip' INTO TABLE census_data.population_data;\"\n",
    "    subprocess.run([\"hive\", \"-e\", hive_query])\n",
    "\n",
    "create_hive_table()\n",
    "load_data_into_hive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_data():\n",
    "    query = \"SELECT * FROM census_data.population_data LIMIT 10;\"\n",
    "    result = subprocess.run([\"hive\", \"-e\", query], capture_output=True, text=True)\n",
    "    print(result.stdout)\n",
    "\n",
    "verify_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
